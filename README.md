# RAG-based Document Retrieval System

![image](https://github.com/Ohmdatazwld5/RAG-for-Document-Retrieval-System/assets/130119515/797e7a7a-a5b2-4192-9615-852e9e2f6279)

![image](https://github.com/Ohmdatazwld5/RAG-for-Document-Retrieval-System/assets/130119515/6d16d9f7-6fdd-42c8-8654-bd0c209992e3)

-Why RAG?
LLMs, although capable of generating text that is both meaningful and grammatically correct, these LLMs suffer from a problem called 'hallucination'. Hallucination in LLMs is the concept where the LLMs confidently generate wrong answers, that is they make up the wrong answers in a way that makes us believe that is true. This has been a major problem since the introduction of the LLMs. These hallucinations lead to incorrect and factually wrong answers.

-Chunking:
Chunking is the process in which we break down a bigger document into smaller pices. There are many chunking stategies there.The simple one is fixed-size chunks. Chosing a chunking strategy has a direct impact on the performance of your system and quality of answers you get.

- Embeddings:
  Embeddings are a way to convert text into a long list of numbers. These numbers are special because they dont only capture words but also meanings and relationships between words. Embeddings also referred as vectors.
